name: Deploy to Google Cloud Run

on:
  push:
    branches:
      - main
  workflow_dispatch:  # Allows manual triggering

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  SERVICE_NAME: mt5-websocket-client
  REGION: us-central1
  MT5_SERVER_URL: ${{ secrets.MT5_SERVER_URL }}
  FOREX_SYMBOLS: ${{ secrets.FOREX_SYMBOLS }}
  STORAGE_TYPE: bigquery
  BQ_DATASET_ID: ${{ secrets.BQ_DATASET_ID }}
  BQ_TABLE_ID: ${{ secrets.BQ_TABLE_ID }}

jobs:
  setup-build-deploy:
    name: Setup, Build, and Deploy
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Setup Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v1
      with:
        project_id: ${{ env.PROJECT_ID }}
        service_account_key: ${{ secrets.GCP_SA_KEY }}
        export_default_credentials: true

    - name: Authenticate with Google Cloud
      run: |
        gcloud auth configure-docker

    - name: Update requirements.txt
      run: |
        # Ensure google-cloud-bigquery is in requirements.txt
        if ! grep -q "google-cloud-bigquery" mt5-websocket-client/requirements.txt; then
          echo "google-cloud-bigquery==3.11.3" >> mt5-websocket-client/requirements.txt
        fi

    - name: Build and Push Docker image
      working-directory: ./mt5-websocket-client
      run: |
        docker build -t gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }} .
        docker push gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }}

    - name: Deploy to Cloud Run
      id: deploy
      uses: google-github-actions/deploy-cloudrun@v1
      with:
        service: ${{ env.SERVICE_NAME }}
        image: gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }}
        region: ${{ env.REGION }}
        env_vars: |
          MT5_SERVER_URL=${{ env.MT5_SERVER_URL }}
          FOREX_SYMBOLS=${{ env.FOREX_SYMBOLS }}
          STORAGE_TYPE=${{ env.STORAGE_TYPE }}
          BQ_DATASET_ID=${{ env.BQ_DATASET_ID }}
          BQ_TABLE_ID=${{ env.BQ_TABLE_ID }}
        flags: |
          --cpu=1
          --memory=512Mi
          --timeout=3600
          --min-instances=1
          --concurrency=1
          --allow-unauthenticated

    - name: Setup BigQuery Dataset if needed
      run: |
        # Check if dataset exists, create if it doesn't
        if ! gcloud alpha bq datasets describe ${{ env.BQ_DATASET_ID }} --project=${{ env.PROJECT_ID }} &> /dev/null; then
          echo "Creating BigQuery dataset: ${{ env.BQ_DATASET_ID }}"
          gcloud alpha bq datasets create ${{ env.BQ_DATASET_ID }} --project=${{ env.PROJECT_ID }} --location=US
        else
          echo "BigQuery dataset ${{ env.BQ_DATASET_ID }} already exists"
        fi

    - name: Setup IAM permissions for BigQuery
      run: |
        SERVICE_ACCOUNT=$(gcloud run services describe ${{ env.SERVICE_NAME }} --platform managed --region ${{ env.REGION }} --format="value(serviceAccountEmail)")
        
        # Grant BigQuery Data Editor role to the service account
        echo "Setting up BigQuery permissions for service account: $SERVICE_ACCOUNT"
        gcloud projects add-iam-policy-binding ${{ env.PROJECT_ID }} \
          --member="serviceAccount:$SERVICE_ACCOUNT" \
          --role="roles/bigquery.dataEditor"
        
        # Also grant BigQuery Job User role to allow creating tables
        gcloud projects add-iam-policy-binding ${{ env.PROJECT_ID }} \
          --member="serviceAccount:$SERVICE_ACCOUNT" \
          --role="roles/bigquery.jobUser"

    - name: Create Cloud Scheduler job to keep service alive
      run: |
        SERVICE_URL=$(gcloud run services describe ${{ env.SERVICE_NAME }} --platform managed --region ${{ env.REGION }} --format="value(status.url)")
        SERVICE_ACCOUNT=$(gcloud run services describe ${{ env.SERVICE_NAME }} --platform managed --region ${{ env.REGION }} --format="value(serviceAccountEmail)")
        
        # Check if scheduler job already exists
        if gcloud scheduler jobs describe keep-${{ env.SERVICE_NAME }}-alive --location=${{ env.REGION }} 2>/dev/null; then
          echo "Updating existing scheduler job..."
          gcloud scheduler jobs update http keep-${{ env.SERVICE_NAME }}-alive \
            --location=${{ env.REGION }} \
            --schedule="*/15 * * * *" \
            --uri="$SERVICE_URL" \
            --http-method=GET \
            --oidc-service-account-email=$SERVICE_ACCOUNT
        else
          echo "Creating new scheduler job..."
          gcloud scheduler jobs create http keep-${{ env.SERVICE_NAME }}-alive \
            --location=${{ env.REGION }} \
            --schedule="*/15 * * * *" \
            --uri="$SERVICE_URL" \
            --http-method=GET \
            --oidc-service-account-email=$SERVICE_ACCOUNT
        fi

    - name: Print deployment information
      run: |
        echo "Service URL: $(gcloud run services describe ${{ env.SERVICE_NAME }} --platform managed --region ${{ env.REGION }} --format='value(status.url)')"
        echo "BigQuery Dataset: ${{ env.BQ_DATASET_ID }}"
        echo "Base Table ID: ${{ env.BQ_TABLE_ID }}_<symbol>"
        echo "Cloud Scheduler: keep-${{ env.SERVICE_NAME }}-alive (runs every 15 minutes)"
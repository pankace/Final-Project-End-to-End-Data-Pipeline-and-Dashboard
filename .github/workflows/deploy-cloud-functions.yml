name: Deploy MT5 Cloud Functions

on:
  push:
    branches:
      - main
    paths:
      - 'src/**'
      - 'terraform/**'
      - '.github/workflows/deploy-cloud-functions.yml'
  workflow_dispatch:  # Allows manual triggering

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-central1
  SERVICE_ACCOUNT_EMAIL: ${{ secrets.GCP_SA_EMAIL }}
  TERRAFORM_STATE_BUCKET: ${{ secrets.TERRAFORM_STATE_BUCKET }}
  GCS_FUNCTION_BUCKET: "${{ secrets.GCP_PROJECT_ID }}-function-bucket"
  BQ_DATASET: "mt5_trading"
  PUBSUB_TOPIC: "mt5-trading-topic"
  HTTP_FUNCTION_NAME: "mt5-http-function"
  PUBSUB_FUNCTION_NAME: "mt5-pubsub-function"

jobs:
  deploy:
    name: Deploy Cloud Functions
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install google-cloud-bigquery google-cloud-pubsub functions-framework

    - name: Authenticate to Google Cloud
      uses: 'google-github-actions/auth@v1'
      with:
        credentials_json: '${{ secrets.GCP_SA_KEY }}'

    - name: Set up Cloud SDK
      uses: 'google-github-actions/setup-gcloud@v1'

    - name: Check for existing resources
      id: check-resources
      run: |
        # Check BigQuery dataset
        if gcloud bigquery datasets describe ${{ env.BQ_DATASET }} --project=${{ env.PROJECT_ID }} &> /dev/null; then
          echo "BQ_DATASET_EXISTS=true" >> $GITHUB_ENV
          echo "BigQuery dataset ${{ env.BQ_DATASET }} exists"
        else
          echo "BQ_DATASET_EXISTS=false" >> $GITHUB_ENV
          echo "BigQuery dataset ${{ env.BQ_DATASET }} does not exist"
        fi
        
        # Check GCS bucket
        if gsutil ls -p ${{ env.PROJECT_ID }} gs://${{ env.GCS_FUNCTION_BUCKET }} &> /dev/null; then
          echo "BUCKET_EXISTS=true" >> $GITHUB_ENV
          echo "GCS bucket ${{ env.GCS_FUNCTION_BUCKET }} exists"
        else
          echo "BUCKET_EXISTS=false" >> $GITHUB_ENV
          echo "GCS bucket ${{ env.GCS_FUNCTION_BUCKET }} does not exist"
        fi
        
        # Check Pub/Sub topic
        if gcloud pubsub topics describe ${{ env.PUBSUB_TOPIC }} --project=${{ env.PROJECT_ID }} &> /dev/null; then
          echo "TOPIC_EXISTS=true" >> $GITHUB_ENV
          echo "Pub/Sub topic ${{ env.PUBSUB_TOPIC }} exists"
        else
          echo "TOPIC_EXISTS=false" >> $GITHUB_ENV
          echo "Pub/Sub topic ${{ env.PUBSUB_TOPIC }} does not exist"
        fi
        
        # Check Cloud Functions
        if gcloud functions describe ${{ env.HTTP_FUNCTION_NAME }} --gen2 --region=${{ env.REGION }} --project=${{ env.PROJECT_ID }} &> /dev/null; then
          echo "HTTP_FUNCTION_EXISTS=true" >> $GITHUB_ENV
          echo "Cloud function ${{ env.HTTP_FUNCTION_NAME }} exists"
        else
          echo "HTTP_FUNCTION_EXISTS=false" >> $GITHUB_ENV
          echo "Cloud function ${{ env.HTTP_FUNCTION_NAME }} does not exist"
        fi
        
        if gcloud functions describe ${{ env.PUBSUB_FUNCTION_NAME }} --gen2 --region=${{ env.REGION }} --project=${{ env.PROJECT_ID }} &> /dev/null; then
          echo "PUBSUB_FUNCTION_EXISTS=true" >> $GITHUB_ENV
          echo "Cloud function ${{ env.PUBSUB_FUNCTION_NAME }} exists"
        else
          echo "PUBSUB_FUNCTION_EXISTS=false" >> $GITHUB_ENV
          echo "Cloud function ${{ env.PUBSUB_FUNCTION_NAME }} does not exist"
        fi

    - name: Prepare function deployment directories
      run: |
        mkdir -p function_deploy/http_function function_deploy/pubsub_function

        # Copy the functions but modify imports to use relative paths
        cat src/cloud_functions/http_function.py | sed 's/from src\./from ./g' > function_deploy/http_function/main.py
        cat src/cloud_functions/pubsub_function.py | sed 's/from src\./from ./g' > function_deploy/pubsub_function/main.py

        # Copy other modules at the correct level
        cp -r src/connectors function_deploy/http_function/
        cp -r src/processors function_deploy/http_function/
        cp -r src/config function_deploy/http_function/

        cp -r src/connectors function_deploy/pubsub_function/
        cp -r src/processors function_deploy/pubsub_function/
        cp -r src/config function_deploy/pubsub_function/

        # Create __init__.py files for proper importing
        touch function_deploy/http_function/__init__.py
        touch function_deploy/http_function/connectors/__init__.py
        touch function_deploy/http_function/processors/__init__.py
        touch function_deploy/http_function/config/__init__.py

        touch function_deploy/pubsub_function/__init__.py
        touch function_deploy/pubsub_function/connectors/__init__.py
        touch function_deploy/pubsub_function/processors/__init__.py
        touch function_deploy/pubsub_function/config/__init__.py

        # Create requirements.txt for each function with gunicorn for better production serving
        cat > function_deploy/http_function/requirements.txt << EOF
        functions-framework>=3.0.0
        google-cloud-bigquery>=3.3.5
        Flask>=2.0.0
        gunicorn>=20.1.0
        EOF

        cat > function_deploy/pubsub_function/requirements.txt << EOF
        functions-framework>=3.0.0
        google-cloud-bigquery>=3.3.5
        gunicorn>=20.1.0
        EOF

        # Update settings.py with environment variables
        sed -i "s/BQ_PROJECT_ID = \"your-project-id\"/BQ_PROJECT_ID = os.environ.get(\"PROJECT_ID\", \"${{ env.PROJECT_ID }}\")/" function_deploy/http_function/config/settings.py
        sed -i "s/BQ_PROJECT_ID = \"your-project-id\"/BQ_PROJECT_ID = os.environ.get(\"PROJECT_ID\", \"${{ env.PROJECT_ID }}\")/" function_deploy/pubsub_function/config/settings.py

        # Create server.py files to properly handle PORT environment variable binding
        cat > function_deploy/http_function/server.py << EOF
        import os
        import functions_framework
        from main import process_mt5_data

        if __name__ == "__main__":
            port = int(os.environ.get("PORT", 8080))
            functions_framework.start(target=process_mt5_data, port=port)
        EOF

        cat > function_deploy/pubsub_function/server.py << EOF
        import os
        import functions_framework
        from main import pubsub_function

        if __name__ == "__main__":
            port = int(os.environ.get("PORT", 8080))
            functions_framework.start(target=pubsub_function, port=port)
        EOF

        # Create .gcloudignore files to prevent uploading unnecessary files
        cat > function_deploy/http_function/.gcloudignore << EOF
        .git
        .gitignore
        .github
        .pytest_cache
        __pycache__/
        *.py[cod]
        *$py.class
        *.so
        EOF

        cat > function_deploy/pubsub_function/.gcloudignore << EOF
        .git
        .gitignore
        .github
        .pytest_cache
        __pycache__/
        *.py[cod]
        *$py.class
        *.so
        EOF

        # Add startup script for Cloud Functions container
        cat > function_deploy/http_function/startup.sh << EOF
        #!/bin/bash
        python server.py
        EOF

        cat > function_deploy/pubsub_function/startup.sh << EOF
        #!/bin/bash
        python server.py
        EOF

        chmod +x function_deploy/http_function/startup.sh
        chmod +x function_deploy/pubsub_function/startup.sh

        # Print directory structure for verification
        echo "Function deployment directories prepared:"
        find function_deploy -type f | sort
        - name: Setup Terraform
          uses: hashicorp/setup-terraform@v2
          with:
            terraform_version: 1.0.0
            terraform_wrapper: false

    - name: Terraform Init
      working-directory: terraform
      run: |
        terraform init \
          -backend-config="bucket=${{ env.TERRAFORM_STATE_BUCKET }}" \
          -backend-config="prefix=terraform/state"

    - name: Check Terraform state
      working-directory: terraform
      run: |
        # List resources in state
        echo "Resources currently in Terraform state:"
        terraform state list || echo "No resources in state"
        
        # If needed, remove resources from state to allow re-importing
        RESOURCES_TO_REMOVE=()
        
        if [ "${{ env.BQ_DATASET_EXISTS }}" == "true" ]; then
          RESOURCES_TO_REMOVE+=(google_bigquery_dataset.mt5_trading[0])
        fi
        
        if [ "${{ env.BUCKET_EXISTS }}" == "true" ]; then
          RESOURCES_TO_REMOVE+=(google_storage_bucket.function_bucket[0])
        fi
        
        if [ "${{ env.TOPIC_EXISTS }}" == "true" ]; then
          RESOURCES_TO_REMOVE+=(google_pubsub_topic.mt5_topic[0])
        fi
        
        if [ "${{ env.HTTP_FUNCTION_EXISTS }}" == "true" ]; then
          RESOURCES_TO_REMOVE+=(google_cloudfunctions2_function.http_function[0])
        fi
        
        if [ "${{ env.PUBSUB_FUNCTION_EXISTS }}" == "true" ]; then
          RESOURCES_TO_REMOVE+=(google_cloudfunctions2_function.pubsub_function[0])
        fi
        
        # Remove resources from state if they already exist
        for resource in "${RESOURCES_TO_REMOVE[@]}"; do
          echo "Removing $resource from state to allow re-import"
          terraform state rm "$resource" || echo "Resource $resource not in state"
        done

    - name: Set Terraform environment variables
      run: |
        echo "TF_VAR_project_id=${{ env.PROJECT_ID }}" >> $GITHUB_ENV
        echo "TF_VAR_region=${{ env.REGION }}" >> $GITHUB_ENV
        echo "TF_VAR_service_account_email=${{ env.SERVICE_ACCOUNT_EMAIL }}" >> $GITHUB_ENV
        echo "TF_VAR_bigquery_dataset=${{ env.BQ_DATASET }}" >> $GITHUB_ENV
        echo "TF_VAR_cloud_function_memory=256" >> $GITHUB_ENV
        echo "TF_VAR_cloud_function_timeout=60" >> $GITHUB_ENV
        
        # Set create_* variables based on what exists - set to false for existing resources
        echo "TF_VAR_create_bigquery_dataset=${{ env.BQ_DATASET_EXISTS == 'false' }}" >> $GITHUB_ENV
        echo "TF_VAR_create_storage_bucket=${{ env.BUCKET_EXISTS == 'false' }}" >> $GITHUB_ENV
        echo "TF_VAR_create_pubsub_topic=${{ env.TOPIC_EXISTS == 'false' }}" >> $GITHUB_ENV
        echo "TF_VAR_create_http_function=${{ env.HTTP_FUNCTION_EXISTS == 'false' }}" >> $GITHUB_ENV
        echo "TF_VAR_create_pubsub_function=${{ env.PUBSUB_FUNCTION_EXISTS == 'false' }}" >> $GITHUB_ENV

    - name: Import existing resources
      working-directory: terraform
      run: |
        # Only import resources that exist but aren't in state
        if [ "${{ env.BQ_DATASET_EXISTS }}" == "true" ]; then
          echo "Importing BigQuery dataset..."
          terraform import google_bigquery_dataset.mt5_trading[0] ${{ env.PROJECT_ID }}:${{ env.BQ_DATASET }} || echo "Failed to import BigQuery dataset"
        fi
        
        if [ "${{ env.BUCKET_EXISTS }}" == "true" ]; then
          echo "Importing storage bucket..."
          terraform import google_storage_bucket.function_bucket[0] ${{ env.GCS_FUNCTION_BUCKET }} || echo "Failed to import storage bucket"
        fi
        
        if [ "${{ env.TOPIC_EXISTS }}" == "true" ]; then
          echo "Importing Pub/Sub topic..."
          terraform import google_pubsub_topic.mt5_topic[0] projects/${{ env.PROJECT_ID }}/topics/${{ env.PUBSUB_TOPIC }} || echo "Failed to import Pub/Sub topic"
        fi
        
        if [ "${{ env.HTTP_FUNCTION_EXISTS }}" == "true" ]; then
          echo "Importing HTTP function..."
          terraform import google_cloudfunctions2_function.http_function[0] projects/${{ env.PROJECT_ID }}/locations/${{ env.REGION }}/functions/${{ env.HTTP_FUNCTION_NAME }} || echo "Failed to import HTTP function"
        fi
        
        if [ "${{ env.PUBSUB_FUNCTION_EXISTS }}" == "true" ]; then
          echo "Importing PubSub function..."
          terraform import google_cloudfunctions2_function.pubsub_function[0] projects/${{ env.PROJECT_ID }}/locations/${{ env.REGION }}/functions/${{ env.PUBSUB_FUNCTION_NAME }} || echo "Failed to import PubSub function"
        fi

    - name: Terraform Validate
      working-directory: terraform
      run: terraform validate

    - name: Terraform Plan
      working-directory: terraform
      run: terraform plan

    - name: Terraform Apply
      working-directory: terraform
      run: terraform apply -auto-approve

    - name: Output deployed function details
      working-directory: terraform
      run: |
        echo "HTTP Function URL: $(terraform output -raw cloud_function_http_url || echo 'Output not available')"
        echo "Pub/Sub Function Name: $(terraform output -raw cloud_function_pubsub_name || echo 'Output not available')"